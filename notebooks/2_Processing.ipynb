{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2   # Change to %autoreload when development phase is over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "## Import library for temporary files creation \n",
    "import tempfile \n",
    "## Import library for time management \n",
    "import time\n",
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Pandas library\n",
    "import pandas as pd\n",
    "## Import Numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Import Matplotlib \n",
    "import matplotlib as mpl \n",
    "## agg backend is used to create plot as a .png file\n",
    "mpl.use('agg')\n",
    "## Import Matplotlib.pyplot for creating graphs\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Environment variables when working on Linux Mint **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 9 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/bin:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/script:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 25466 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/25383,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/25383 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 9 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass/script \t\n",
      "GISBASE = /home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 11635 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c22 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-FzQKwSsyzM,guid=573684252e16c96c145a408a5be69c31 \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1541839920.911260-2123598289 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 83886086 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/data/Dropbox/ULB/MAUPP/Traitements/population_modeling/notebooks \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/lib/python2.7 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "## Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Functions defined by the user **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb\n",
    "from grass_database import check_location\n",
    "from grass_database import check_mapset\n",
    "from grass_database import working_mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import functions for processing time information\n",
    "from processing_time import start_processing\n",
    "from processing_time import print_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that create color file for raster\n",
    "from colorise_raster import create_color_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that clip multiple raster according to extention of a vector layer\n",
    "from create_clumped_grid import create_clumped_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the path to the directory you want to use as \"[GRASSDATA](https://grass.osgeo.org/programming7/loc_struct.png)\". \n",
    "- Enter the name of the location in which you want to work and its projection information in [EPSG code](http://spatialreference.org/ref/epsg/) format. Please note that the GRASSDATA folder and locations will be automatically created if not existing yet. If the location name already exists, the projection information will not be used.  \n",
    "- Enter the name you want for the mapsets which will be used later for Unsupervised Segmentation Parameter Optimization (USPO), Segmentation and Classification steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define a empty dictionnary for saving user inputs\n",
    "user={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the path to GRASSDATA folder\n",
    "user[\"gisdb\"] = \"/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/GRASSDATA\"\n",
    "## Enter the name of the location (existing or for a new one)\n",
    "user[\"location\"] = \"Dakar_32628\"\n",
    "## Enter the EPSG code for this location \n",
    "user[\"locationepsg\"] = \"32628\"\n",
    "## Enter the name of the permanent mapset\n",
    "user[\"permanent_mapset\"] = \"PERMANENT\"\n",
    "## Enter the name of a working mapset\n",
    "user[\"dasym_mapset\"] = \"DASYMETRY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Check for existance of GRASSDATA folder, location and mapsets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the python script will check if GRASSDATA folder, locations and mapsets already exist. If not, they will be automatically created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRASSDATA folder already exist\n"
     ]
    }
   ],
   "source": [
    "# Check if the GRASS GIS database exists and create it if not\n",
    "check_gisdb(user[\"gisdb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Dakar_32628 already exist\n"
     ]
    }
   ],
   "source": [
    "# Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "check_location(user[\"gisdb\"],user[\"location\"],user[\"locationepsg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PERMANENT' mapset already exists in location 'Dakar_32628'\n"
     ]
    }
   ],
   "source": [
    "# Check if the mapset exists and create it if not\n",
    "check_mapset(user[\"gisdb\"],user[\"location\"],user[\"permanent_mapset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DASYMETRY' mapset already exists in location 'Dakar_32628'\n"
     ]
    }
   ],
   "source": [
    "# Check if the mapset exists and create it if not\n",
    "check_mapset(user[\"gisdb\"],user[\"location\"],user[\"dasym_mapset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch GRASS GIS working session on DASYMETRY mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now working in mapset 'DASYMETRY'\n"
     ]
    }
   ],
   "source": [
    "# Change the current working GRASS GIS session mapset\n",
    "working_mapset(user[\"gisdb\"],user[\"location\"],user[\"dasym_mapset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the name of main layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the name of the layers\n",
    "Land_cover = 'landcover'  # VHR Land cover map\n",
    "Land_use = 'landuse' # VHR Land use map\n",
    "mr_builtup = 'MR_builtup' # MR built-up map\n",
    "grid = 'clumped_grid'\n",
    "## Name of the column containing the population count\n",
    "population_column=\"POPULATION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the resolution of the prediction grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tile_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set several variables and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare list that will contain the name/paths of temporary layers/files\n",
    "TMP_MAPS = []\n",
    "TMP_CSV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare strings that will contain the log of the processing\n",
    "log_text = \"\"\n",
    "log_text_extend = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of job that could be runned in parallel\n",
    "n_jobs = 10\n",
    "# Check if the computer has enough cores\n",
    "if(n_jobs >= multiprocessing.cpu_count()):\n",
    "    gscript.fatal(_(\"Requested number of jobs is > or = to available ressources. \\\n",
    "                    Try to reduce to at maximum <%s> jobs\")%(int(multiprocessing.cpu_count())-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary directories for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_tempdirs(list_of_directories):\n",
    "    '''\n",
    "    Function that create needed temporary folder. Those name have to be saved as other function will depend of the name of those folder.\n",
    "    '''\n",
    "    return_list = []\n",
    "    tmp_grass_dir=gscript.tempdir()\n",
    "    \n",
    "    for directory in list_of_directories:    \n",
    "        # Temporary directory for administrative units statistics\n",
    "        outputdirectory=os.path.join(tmp_grass_dir,directory)\n",
    "        if not os.path.exists(outputdirectory):\n",
    "            os.makedirs(outputdirectory)\n",
    "        return_list.append(outputdirectory)\n",
    "    # Return paths\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary folder and get their paths\n",
    "outputdirectory_admin, outputdirectory_grid = create_tempdirs([\"admin_level\", \"grid_level\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a clumped grid for dasymetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This grid will be the reference grid for re-allocation of population count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clumped grid\n",
    "create_clumped_grid(tile_size=tile_size, mask_raster=Land_cover, output='clumped_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create layers with grid boundary for both levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridded_admin_boundaries(input_vector, id, pop_column, grid):\n",
    "    '''\n",
    "    Function convecting the vector to raster then raster to vector: boundaries will have a \"staircase\" appearence\n",
    "    so that each tile of the gridded vector will be contained in only one administrative unit\n",
    "    '''\n",
    "    \n",
    "    def check_no_missing_zones(vector_origin, vector_gridded, resolution):\n",
    "        '''\n",
    "        Function checking if the number of items (admin zones) in the original vector provided by the user is wall conserved after the rasterization.\n",
    "        If the original vector contains small sized polygons (or very tight) and desired 'tile_size' is too large, some polygons could disappeared during the rasterization process\n",
    "        '''\n",
    "        origin_n=gscript.parse_command('v.db.univar', flags='g', map=vector_origin, column='cat')['n']\n",
    "        gridded_n=gscript.parse_command('v.db.univar', flags='g', map=vector_gridded, column='cat')['n']\n",
    "        if origin_n != gridded_n:\n",
    "            gscript.run_command('g.remove', quiet=True, type='vector', name=vector_gridded, flags='fb')\n",
    "            message=_((\"A tile size of %s m seems too large and produce loss of some polygons when rasterizing them.\\n\") % resolution)\n",
    "            message+=_((\"Try to reduce the 'tile_size' parameter or edit the <%s> vector to merge smallest administrative units with their neighoring units\") % vector_origin)\n",
    "            gscript.fatal(message)\n",
    "        \n",
    "    current_mapset = gscript.gisenv()['MAPSET']\n",
    "    gscript.run_command('g.region', raster=grid)\n",
    "    resolution = int(float(gscript.parse_command('g.region', flags='pg')['nsres']))\n",
    "    global gridded_admin_units\n",
    "    gridded_admin_units = random_layer_name(prefix='gridded_admin_units')\n",
    "    gridded_vector = input_vector.split(\"@\")[0]+'_'+str(resolution)+'m_gridded'+'@'+current_mapset\n",
    "    gscript.run_command('v.to.rast', quiet=True, input=input_vector, type='area', \n",
    "                        output=gridded_admin_units, use='attr', \n",
    "                        attribute_column=id, overwrite=True)\n",
    "    gscript.run_command('r.to.vect', quiet=True, input=gridded_admin_units, \n",
    "                        output=gridded_vector, type='area', column=id, \n",
    "                        flags='v',overwrite=True)\n",
    "    tmp_name=random_layer_name()\n",
    "    gscript.run_command('g.copy', quiet=True, vector='%s,%s'%(input_vector,tmp_name))\n",
    "    gscript.run_command('v.db.join', quiet=True, map_=gridded_vector, column='cat', other_table=tmp_name, other_column=id, subset_columns=pop_column) #join the population count\n",
    "    gscript.run_command('g.remove', quiet=True, flags='f', type='vector', name=tmp_name+'@'+current_mapset)\n",
    "    check_no_missing_zones(input_vector, gridded_vector, resolution)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create layer with boundaries corresponding to the grid \n",
    "gridded_admin_boundaries(\"admin_level0\", 'cluster', population_column, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of values from categorical raster (land cover and land use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Data_prep(categorical_raster):\n",
    "    '''\n",
    "    Function that extracts resolution and sorted list of classes of \n",
    "    a categorical raster (like land cover or land use information).\n",
    "    '''\n",
    "    info = gscript.raster_info(categorical_raster)\n",
    "    nsres=info.nsres\n",
    "    ewres=info.ewres\n",
    "    L = []\n",
    "    L=[cl.split(\"\t\")[0] for cl in gscript.parse_command('r.category',map=categorical_raster)]\n",
    "    for i,x in enumerate(L):  #Make sure the format is UTF8 and not Unicode\n",
    "        L[i]=x.encode('UTF8')\n",
    "    L.sort(key=float) #Sort the raster categories in ascending.\n",
    "    return nsres, ewres, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of raster 'landcover' used: 10,22,23,33,34,45,111,112,113\n"
     ]
    }
   ],
   "source": [
    "# Data preparation : extract list of classes from the Land Cover\n",
    "lc_classes_list = Data_prep(Land_cover)[2]\n",
    "message=\"Classes of raster '\"+str(Land_cover)+\"' used: \"+\",\".join(lc_classes_list)\n",
    "log_text+=message+'\\n'\n",
    "print message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of raster 'landuse' used: 1,2,3,4,5,6,7,8\n"
     ]
    }
   ],
   "source": [
    "# Data preparation : extract list of classes from the land use\n",
    "lu_classes_list = Data_prep(Land_use)[2]\n",
    "message=\"Classes of raster '\"+str(Land_use)+\"' used: \"+\",\".join(lu_classes_list)\n",
    "log_text+=message+'\\n'\n",
    "print message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute proportion of each land cover and land use class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportion_class(rasterLayer, cl):\n",
    "    '''\n",
    "    Function extracting a binary map for class 'cl' in raster 'rasterLayer', then computing the proportion of this class in both administratives units and in grids.\n",
    "    The computational region should be defined properly before running this function.\n",
    "    '''\n",
    "    #global outputdirectory_admin, outputdirectory_grid\n",
    "    #Set the region to match the extend of the raster\n",
    "    ### Create a binary raster for the current class\n",
    "    prefix = 'LC' if rasterLayer == Land_cover.split(\"@\")[0] else 'LU'  # Adaptative prefix according to the input raster (land_cover of land_use)\n",
    "    binary_raster = prefix+\"_\"+cl  # Set the name of the binary raster\n",
    "    gscript.run_command('r.mapcalc', expression='%s=if(%s==%s,1,0)'%(binary_raster,rasterLayer,cl),\n",
    "                        overwrite=True,quiet=True) # Mapcalc to create binary raster for the expected class 'cl'\n",
    "    ### Create a temporary copy of the current binary raster with all pixels values equal to 1 (to be used for computing proportion of current binary class)\n",
    "    tmplayer = random_layer_name(prefix='tmp_%s'%binary_raster)\n",
    "    gscript.run_command('r.mapcalc', expression='%s=if(%s==1,1,1)'%(tmplayer,binary_raster),\n",
    "                        overwrite=True,quiet=True)\n",
    "    # Fill potential remaining null values with 0 value (when using r.mapcalc, null values existing in the 'rasterLayer' will remain null in the binary)\n",
    "    gscript.run_command('r.null', quiet=True, map=binary_raster, null='0')\n",
    "    gscript.run_command('r.null', quiet=True, map=tmplayer, null='0')\n",
    "    \n",
    "    ### Compute proportion of pixels of the current class - Administrative units\n",
    "    stat_csv=os.path.join(outputdirectory_admin,\"%s_%s.csv\"%(prefix,cl))\n",
    "    ref_map = gridded_admin_units\n",
    "    gscript.run_command('i.segment.stats', flags='s', map=ref_map, rasters='%s,%s'%(tmplayer,binary_raster), raster_statistics='sum', csvfile=stat_csv, separator='comma', quiet=True, overwrite=True)\n",
    "    output_csv_1=compute_proportion_csv(stat_csv) #Create a new csv containing the proportion\n",
    "    ### Compute proportion of pixels of the current class - Grids\n",
    "    stat_csv=os.path.join(outputdirectory_grid,\"%s_%s.csv\"%(prefix,cl))\n",
    "    ref_map='clumped_grid'\n",
    "    gscript.run_command('i.segment.stats', flags='s', map=ref_map, rasters='%s,%s'%(tmplayer,binary_raster), raster_statistics='sum', csvfile=stat_csv, separator='comma', quiet=True, overwrite=True)\n",
    "    output_csv_2=compute_proportion_csv(stat_csv) #Create a new csv containing the proportion\n",
    "    \n",
    "    ### Remove temporary layer\n",
    "    gscript.run_command('g.remove', quiet=True, flags='f',type='raster',name=tmplayer)\n",
    "    # Return lists\n",
    "    return (binary_raster,output_csv_1,output_csv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def compute_proportion_csv(infile):\n",
    "    '''\n",
    "    Function used in 'proportion_class' function. It take as input the csv from i.segment.stats with the area (in number of pixels)\n",
    "    the sum of pixels of the binary raster and create a new csv with the proportion\n",
    "    '''\n",
    "    # Set the path to the outputfile\n",
    "    head, tail = os.path.split(infile)\n",
    "    root, ext = os.path.splitext(tail)\n",
    "    outfile=os.path.join(head,root+\"_prop\"+ext)\n",
    "    # Create new csv reader and writer objects\n",
    "    reader=csv.reader(open(infile,'r'), delimiter=\",\")\n",
    "    writer=csv.writer(open(outfile,'w'), delimiter=\",\")\n",
    "    # Initialize empty lists\n",
    "    crash_report=[]\n",
    "    content=[]\n",
    "    # Save the first line as header and create the new header\n",
    "    header=reader.next()\n",
    "    new_header=[]\n",
    "    new_header.append(header[0])\n",
    "    index=header[2].find(\"_sum\")\n",
    "    new_header.append(header[2][:index]+'_proportion')\n",
    "    content.append(new_header)  #Create new header with first original column and current class related name for proportion\n",
    "    # Loop through the rest of the rows (header is passed)\n",
    "    for row in reader:\n",
    "        pix_nb=float(row[1]) #Area of the unit (in number of pixels)\n",
    "        class_nb=float(row[2]) #Number of pixels of current class (binary raster)\n",
    "        try:\n",
    "            prop=100*class_nb/pix_nb\n",
    "            content.append([row[0],\"{0:.5f}\".format(prop)])\n",
    "        except ZeroDivisionError:  #If computation of proportion failed because of 'ZeroDivisionError'\n",
    "            crash_report.append(row[0])\n",
    "            content.append([row[0],\"{0:.5f}\".format(0.0)])  # If ZeroDivisionError, set the proportion to zero to avoid errors in next steps\n",
    "            continue\n",
    "    writer.writerows(content)\n",
    "    os.remove(infile)\n",
    "    # Print notification of ZeroDivisionError if it happened\n",
    "    if len(crash_report)>0:\n",
    "        print \"An 'ZeroDivisionError' has been registered for the following <%s>\"%header[0]+\"\\n\".join(crash_report)\n",
    "    # Return the path to the temporary csv file\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land cover proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save time at starting\n",
    "start = start_processing() \n",
    "## Compute proportion of each class of categorical raster (parallel processing).\n",
    "gscript.run_command('g.region', raster=Land_cover.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "p=Pool(n_jobs) #Create a 'pool' of processes and launch them using 'map' function\n",
    "func=partial(proportion_class,Land_cover.split(\"@\")[0]) # Set fixed argument of the function\n",
    "output=p.map(func,lc_classes_list) # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "temp_rasterlist,temp_csvlist_1,temp_csvlist_2=zip(*output)\n",
    "[TMP_MAPS.append(x) for x in temp_rasterlist]  # Append the name of binary rasters to the list of temporary maps\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_1]  # Append the paths to .csv files to the list of temporary .csv\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_2]  # Append the paths to .csv files to the list of temporary .csv\n",
    "# Print processing time\n",
    "print_processing_time(begintime=start, printmessage=\"Proportion of each class of categorical raster computed in: \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land use proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save time at starting\n",
    "start = start_processing() \n",
    "## Compute proportion of each class of categorical raster (parallel processing).\n",
    "gscript.run_command('g.region', raster=Land_use.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "p=Pool(n_jobs) #Create a 'pool' of processes and launch them using 'map' function\n",
    "func=partial(proportion_class,Land_use.split(\"@\")[0]) # Set fixed argument of the function\n",
    "output=p.map(func,lu_classes_list) # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "temp_rasterlist,temp_csvlist_1,temp_csvlist_2=zip(*output)\n",
    "[TMP_MAPS.append(x) for x in temp_rasterlist]  # Append the name of binary rasters to the list of temporary maps\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_1]  # Append the paths to .csv files to the list of temporary .csv\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_2]  # Append the paths to .csv files to the list of temporary .csv\n",
    "# Print processing time\n",
    "print_processing_time(begintime=start, printmessage=\"Proportion of each class of categorical raster computed in: \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for landuse\n",
    "if(Land_use != '' ):\n",
    "    gscript.run_command('g.region', raster=Land_use.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "    p=Pool(n_jobs) #Create a 'pool' of processes and launch them using 'map' function\n",
    "    func=partial(proportion_class,Land_use.split(\"@\")[0]) # Set fixed argument of the function\n",
    "    output=p.map(func,lu_classes_list) # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    temp_rasterlist,temp_csvlist_1,temp_csvlist_2=zip(*output)\n",
    "    [TMP_MAPS.append(x) for x in temp_rasterlist]  # Append the name of binary rasters to the list of temporary maps\n",
    "    [TMP_CSV.append(x) for x in temp_csvlist_1]  # Append the paths to .csv files to the list of temporary .csv\n",
    "    [TMP_CSV.append(x) for x in temp_csvlist_2]  # Append the paths to .csv files to the list of temporary .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.population.density.py -a -f --overwrite vector=admin_level0@PERMANENT land_cover=landcover@PERMANENT land_use=landuse@PERMANENT tile_size=100 id=Sect_ID population=pop_Total output=Ouaga_lc_lu_100m_weighting_RF plot=/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Ouagadougou/RF_feature_importance.png log_file=/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Ouagadougou/RF_log n_jobs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Re-allocate population count from level 0 to the grid level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v.area.weigh --overwrite vector=admin_level0_100m_gridded@PERMANENT column=pop_Total weight=Ouaga_lc_lu_100m_weighting_RF@PERMANENT output=Ouaga_lc_lu_100m_pop_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove all temporary layers\n",
    "# raster corresponding to administrative units (level0)\n",
    "gscript.run_command('g.remove', quiet=True, flags='f',type='raster',name=gridded_admin_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
