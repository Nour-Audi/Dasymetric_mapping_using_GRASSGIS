{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2   # Change to %autoreload when development phase is over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is a Javascript section of code for building the Jupyter notebook's table of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed for setting parameters of operating system \n",
    "import os\n",
    "import sys\n",
    "## Import library for temporary files creation \n",
    "import tempfile \n",
    "## Import library for time management \n",
    "import time\n",
    "## Import multiprocessing and functools libraries\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Pandas library\n",
    "import pandas as pd\n",
    "## Import Numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Import Matplotlib \n",
    "import matplotlib as mpl \n",
    "## agg backend is used to create plot as a .png file\n",
    "mpl.use('agg')\n",
    "## Import Matplotlib.pyplot for creating graphs\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add folder with SCR provided belong to this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add local module to the path\n",
    "src = os.path.abspath('../SRC')\n",
    "if src not in sys.path:\n",
    "    sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Environment variables when working on Linux Mint **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import environ_variables as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDMSESSION = mate \t\n",
      "MANDATORY_PATH = /usr/share/gconf/mate.mandatory.path \t\n",
      "MATE_DESKTOP_SESSION_ID = this-is-deprecated \t\n",
      "LESSOPEN = | /usr/bin/lesspipe %s \t\n",
      "MDM_LANG = fr_BE.UTF-8 \t\n",
      "LOGNAME = tais \t\n",
      "USER = tais \t\n",
      "HOME = /home/tais \t\n",
      "XDG_VTNR = 9 \t\n",
      "PATH = /usr/local/bin:/home/tais/BIN:/home/tais/bin:/home/tais/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/bin:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/script:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib \t\n",
      "CLICOLOR = 1 \t\n",
      "DISPLAY = :0.0 \t\n",
      "SSH_AGENT_PID = 25466 \t\n",
      "LANG = fr_BE.UTF-8 \t\n",
      "TERM = xterm-color \t\n",
      "SHELL = /bin/bash \t\n",
      "GIS_LOCK = $$ \t\n",
      "XAUTHORITY = /home/tais/.Xauthority \t\n",
      "SESSION_MANAGER = local/tais-HP-Z620-Workstation:@/tmp/.ICE-unix/25383,unix/tais-HP-Z620-Workstation:/tmp/.ICE-unix/25383 \t\n",
      "SHLVL = 1 \t\n",
      "QT_LINUX_ACCESSIBILITY_ALWAYS_ON = 1 \t\n",
      "INSIDE_CAJA_PYTHON =  \t\n",
      "QT_ACCESSIBILITY = 1 \t\n",
      "LD_LIBRARY_PATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/lib \t\n",
      "COMPIZ_CONFIG_PROFILE = mate \t\n",
      "WINDOWPATH = 9 \t\n",
      "GTK_OVERLAY_SCROLLING = 0 \t\n",
      "PYTHONPATH = :/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass:/home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu/etc/python/grass/script \t\n",
      "GISBASE = /home/tais/SRC/GRASS/grass_trunk/dist.x86_64-pc-linux-gnu \t\n",
      "CLUTTER_BACKEND = x11 \t\n",
      "USERNAME = tais \t\n",
      "XDG_SESSION_DESKTOP = mate \t\n",
      "GDM_XSERVER_LOCATION = local \t\n",
      "XDG_RUNTIME_DIR = /run/user/1000 \t\n",
      "JPY_PARENT_PID = 11635 \t\n",
      "QT_STYLE_OVERRIDE = gtk \t\n",
      "SSH_AUTH_SOCK = /run/user/1000/keyring/ssh \t\n",
      "VTE_VERSION = 4205 \t\n",
      "GDMSESSION = mate \t\n",
      "GISRC = /home/tais/.grass7/rc \t\n",
      "GIT_PAGER = cat \t\n",
      "XDG_CONFIG_DIRS = /etc/xdg/xdg-mate:/etc/xdg \t\n",
      "XDG_CURRENT_DESKTOP = MATE \t\n",
      "XDG_SESSION_ID = c22 \t\n",
      "DBUS_SESSION_BUS_ADDRESS = unix:abstract=/tmp/dbus-FzQKwSsyzM,guid=573684252e16c96c145a408a5be69c31 \t\n",
      "_ = /usr/local/bin/jupyter \t\n",
      "XDG_SESSION_COOKIE = 8441891e86e24d76b9616edf516d5734-1541839920.911260-2123598289 \t\n",
      "DESKTOP_SESSION = mate \t\n",
      "WINDOWID = 83886086 \t\n",
      "LESSCLOSE = /usr/bin/lesspipe %s %s \t\n",
      "DEFAULTS_PATH = /usr/share/gconf/mate.default.path \t\n",
      "MPLBACKEND = module://ipykernel.pylab.backend_inline \t\n",
      "MDM_XSERVER_LOCATION = local \t\n",
      "GTK_MODULES = gail:atk-bridge \t\n",
      "XDG_DATA_DIRS = /usr/share/mate:/usr/local/share/:/usr/share/:/usr/share/mdm/ \t\n",
      "PWD = /media/tais/data/Dropbox/ULB/MAUPP/Traitements/population_modeling/notebooks \t\n",
      "COLORTERM = mate-terminal \t\n",
      "PYTHONLIB = /usr/lib/python2.7 \t\n",
      "LS_COLORS = rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: \t\n",
      "PAGER = cat \t\n",
      "XDG_SEAT = seat0 \t\n"
     ]
    }
   ],
   "source": [
    "# Set environmental variables\n",
    "envi.setup_environmental_variables() \n",
    "# Display current environment variables of your computer\n",
    "envi.print_environmental_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GRASS GIS Python libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries needed to launch GRASS GIS in the jupyter notebook\n",
    "import grass.script.setup as gsetup\n",
    "## Import libraries needed to call GRASS using Python\n",
    "import grass.script as gscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Functions defined by the user **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that check existance and create GRASS GIS database folder if needed\n",
    "from grass_database import check_gisdb\n",
    "from grass_database import check_location\n",
    "from grass_database import check_mapset\n",
    "from grass_database import working_mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import functions for processing time information\n",
    "from processing_time import start_processing\n",
    "from processing_time import print_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that generate a random name in the GRASS GIS environement\n",
    "from random_layer_name import random_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that create color file for raster\n",
    "from colorise_raster import create_color_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import function that clip multiple raster according to extention of a vector layer\n",
    "from create_clumped_grid import create_clumped_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the path to the directory you want to use as \"[GRASSDATA](https://grass.osgeo.org/programming7/loc_struct.png)\". \n",
    "- Enter the name of the location in which you want to work and its projection information in [EPSG code](http://spatialreference.org/ref/epsg/) format. Please note that the GRASSDATA folder and locations will be automatically created if not existing yet. If the location name already exists, the projection information will not be used.  \n",
    "- Enter the name you want for the mapsets which will be used later for Unsupervised Segmentation Parameter Optimization (USPO), Segmentation and Classification steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define a empty dictionnary for saving user inputs\n",
    "user={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Enter the path to GRASSDATA folder\n",
    "user[\"gisdb\"] = \"/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/GRASSDATA\"\n",
    "## Enter the name of the location (existing or for a new one)\n",
    "user[\"location\"] = \"Dakar_32628\"\n",
    "## Enter the EPSG code for this location \n",
    "user[\"locationepsg\"] = \"32628\"\n",
    "## Enter the name of the permanent mapset\n",
    "user[\"permanent_mapset\"] = \"PERMANENT\"\n",
    "## Enter the name of a working mapset\n",
    "user[\"dasym_mapset\"] = \"DASYMETRY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Check for existance of GRASSDATA folder, location and mapsets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the python script will check if GRASSDATA folder, locations and mapsets already exist. If not, they will be automatically created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRASSDATA folder already exist\n"
     ]
    }
   ],
   "source": [
    "# Check if the GRASS GIS database exists and create it if not\n",
    "check_gisdb(user[\"gisdb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Dakar_32628 already exist\n"
     ]
    }
   ],
   "source": [
    "# Check if the location exists and create it if not, with the CRS defined by the epsg code \n",
    "check_location(user[\"gisdb\"],user[\"location\"],user[\"locationepsg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'PERMANENT' mapset already exists in location 'Dakar_32628'\n"
     ]
    }
   ],
   "source": [
    "# Check if the mapset exists and create it if not\n",
    "check_mapset(user[\"gisdb\"],user[\"location\"],user[\"permanent_mapset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DASYMETRY' mapset already exists in location 'Dakar_32628'\n"
     ]
    }
   ],
   "source": [
    "# Check if the mapset exists and create it if not\n",
    "check_mapset(user[\"gisdb\"],user[\"location\"],user[\"dasym_mapset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch GRASS GIS working session on DASYMETRY mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now working in mapset 'DASYMETRY'\n"
     ]
    }
   ],
   "source": [
    "# Change the current working GRASS GIS session mapset\n",
    "working_mapset(user[\"gisdb\"],user[\"location\"],user[\"dasym_mapset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the name of main layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the name of the layers\n",
    "Land_cover = 'landcover'  # VHR Land cover map\n",
    "Land_use = 'landuse' # VHR Land use map\n",
    "mr_builtup = 'MR_builtup' # MR built-up map\n",
    "mr_built_pixelvalue = '1'\n",
    "grid = 'clumped_grid'\n",
    "## Name of the column containing the population count\n",
    "population_column=\"POPULATION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the resolution of the prediction grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tile_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set several variables and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare list that will contain the name/paths of temporary layers/files\n",
    "TMP_MAPS = []\n",
    "TMP_CSV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare strings that will contain the log of the processing\n",
    "log_text = \"\"\n",
    "log_text_extend = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of job that could be runned in parallel\n",
    "n_jobs = 15\n",
    "# Check if the computer has enough cores\n",
    "if(n_jobs >= multiprocessing.cpu_count()):\n",
    "    gscript.fatal(_(\"Requested number of jobs is > or = to available ressources. \\\n",
    "                    Try to reduce to at maximum <%s> jobs\")%(int(multiprocessing.cpu_count())-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary directories for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_tempdirs(list_of_directories):\n",
    "    '''\n",
    "    Function that create needed temporary folder. Those name have to be saved as other function will depend of the name of those folder.\n",
    "    '''\n",
    "    return_list = []\n",
    "    tmp_grass_dir=gscript.tempdir()\n",
    "    \n",
    "    for directory in list_of_directories:    \n",
    "        # Temporary directory for administrative units statistics\n",
    "        outputdirectory=os.path.join(tmp_grass_dir,directory)\n",
    "        if not os.path.exists(outputdirectory):\n",
    "            os.makedirs(outputdirectory)\n",
    "        return_list.append(outputdirectory)\n",
    "    # Return paths\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary folder and get their paths\n",
    "outputdirectory_admin, outputdirectory_grid = create_tempdirs([\"admin_level\", \"grid_level\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a clumped grid for dasymetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This grid will be the reference grid for re-allocation of population count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a name for the empty grid layer\n",
    "clumped_grid = 'clumped_grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clumped grid\n",
    "create_clumped_grid(tile_size=tile_size, mask_raster=Land_cover, output=clumped_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create layers with grid boundary for both levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridded_admin_boundaries(input_vector, id, pop_column, grid):\n",
    "    '''\n",
    "    Function convecting the vector to raster then raster to vector: boundaries will have a \"staircase\" appearence\n",
    "    so that each tile of the gridded vector will be contained in only one administrative unit\n",
    "    '''\n",
    "    \n",
    "    def check_no_missing_zones(vector_origin, vector_gridded, resolution):\n",
    "        '''\n",
    "        Function checking if the number of items (admin zones) in the original vector provided by the user is wall conserved after the rasterization.\n",
    "        If the original vector contains small sized polygons (or very tight) and desired 'tile_size' is too large, some polygons could disappeared during the rasterization process\n",
    "        '''\n",
    "        origin_n=gscript.parse_command('v.db.univar', flags='g', map=vector_origin, column='cat')['n']\n",
    "        gridded_n=gscript.parse_command('v.db.univar', flags='g', map=vector_gridded, column='cat')['n']\n",
    "        if origin_n != gridded_n:\n",
    "            gscript.run_command('g.remove', quiet=True, type='vector', name=vector_gridded, flags='fb')\n",
    "            message=_((\"A tile size of %s m seems too large and produce loss of some polygons when rasterizing them.\\n\") % resolution)\n",
    "            message+=_((\"Try to reduce the 'tile_size' parameter or edit the <%s> vector to merge smallest administrative units with their neighoring units\") % vector_origin)\n",
    "            gscript.fatal(message)\n",
    "        \n",
    "    current_mapset = gscript.gisenv()['MAPSET']\n",
    "    gscript.run_command('g.region', raster=grid)\n",
    "    resolution = int(float(gscript.parse_command('g.region', flags='pg')['nsres']))\n",
    "    global gridded_admin_units\n",
    "    global gridded_vector\n",
    "    gridded_admin_units = random_layer_name(prefix='gridded_admin_units')\n",
    "    gridded_vector = input_vector.split(\"@\")[0]+'_'+str(resolution)+'m_gridded'\n",
    "    gscript.run_command('v.to.rast', quiet=True, input=input_vector, type='area', \n",
    "                        output=gridded_admin_units, use='attr', \n",
    "                        attribute_column=id, overwrite=True)\n",
    "    gscript.run_command('r.to.vect', quiet=True, input=gridded_admin_units, \n",
    "                        output='%s@%s'%(gridded_vector,current_mapset), type='area', column=id, \n",
    "                        flags='v',overwrite=True)\n",
    "    tmp_name=random_layer_name()\n",
    "    gscript.run_command('g.copy', quiet=True, vector='%s,%s'%(input_vector,tmp_name))\n",
    "    gscript.run_command('v.db.join', quiet=True, map_=gridded_vector, column='cat', other_table=tmp_name, other_column=id, subset_columns=pop_column) #join the population count\n",
    "    gscript.run_command('g.remove', quiet=True, flags='f', type='vector', name=tmp_name+'@'+current_mapset)\n",
    "    check_no_missing_zones(input_vector, gridded_vector, resolution)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create layer with boundaries corresponding to the grid \n",
    "gridded_admin_boundaries(\"admin_level0\", 'cluster', population_column, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of values from categorical raster (land cover and land use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Data_prep(categorical_raster):\n",
    "    '''\n",
    "    Function that extracts resolution and sorted list of classes of \n",
    "    a categorical raster (like land cover or land use information).\n",
    "    '''\n",
    "    info = gscript.raster_info(categorical_raster)\n",
    "    nsres=info.nsres\n",
    "    ewres=info.ewres\n",
    "    L = []\n",
    "    L=[cl.split(\"\t\")[0] for cl in gscript.parse_command('r.category',map=categorical_raster)]\n",
    "    for i,x in enumerate(L):  #Make sure the format is UTF8 and not Unicode\n",
    "        L[i]=x.encode('UTF8')\n",
    "    L.sort(key=float) #Sort the raster categories in ascending.\n",
    "    return nsres, ewres, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of raster 'landcover' used: 10,22,23,33,34,45,111,112,113\n"
     ]
    }
   ],
   "source": [
    "# Data preparation : extract list of classes from the Land Cover\n",
    "lc_classes_list = Data_prep(Land_cover)[2]\n",
    "message=\"Classes of raster '\"+str(Land_cover)+\"' used: \"+\",\".join(lc_classes_list)\n",
    "log_text+=message+'\\n'\n",
    "print message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of raster 'landuse' used: 1,2,3,4,5,6,7,8\n"
     ]
    }
   ],
   "source": [
    "# Data preparation : extract list of classes from the land use\n",
    "lu_classes_list = Data_prep(Land_use)[2]\n",
    "message=\"Classes of raster '\"+str(Land_use)+\"' used: \"+\",\".join(lu_classes_list)\n",
    "log_text+=message+'\\n'\n",
    "print message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute proportion of each land cover and land use class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_class(rasterLayer, cl):\n",
    "    '''\n",
    "    Function extracting a binary map for class 'cl' in raster 'rasterLayer', then computing the proportion of this class in both administratives units and in grids.\n",
    "    The computational region should be defined properly before running this function.\n",
    "    '''\n",
    "    #global outputdirectory_admin, outputdirectory_grid\n",
    "    #Set the region to match the extend of the raster\n",
    "    ### Create a binary raster for the current class\n",
    "    if rasterLayer == Land_cover.split(\"@\")[0]:\n",
    "        prefix = 'LC' \n",
    "    elif rasterLayer == Land_use.split(\"@\")[0]:\n",
    "        prefix = 'LU' \n",
    "    else: prefix = 'MR'  \n",
    "    # Adaptative prefix according to the input raster (land_cover of land_use)\n",
    "    binary_raster = prefix+\"_\"+cl  # Set the name of the binary raster\n",
    "    gscript.run_command('r.mapcalc', expression='%s=if(%s==%s,1,0)'%(binary_raster,rasterLayer,cl),\n",
    "                        overwrite=True,quiet=True) # Mapcalc to create binary raster for the expected class 'cl'\n",
    "    ### Create a temporary copy of the current binary raster with all pixels values equal to 1 (to be used for computing proportion of current binary class)\n",
    "    tmplayer = random_layer_name(prefix='tmp_%s'%binary_raster)\n",
    "    gscript.run_command('r.mapcalc', expression='%s=if(%s==1,1,1)'%(tmplayer,binary_raster),\n",
    "                        overwrite=True,quiet=True)\n",
    "    # Fill potential remaining null values with 0 value (when using r.mapcalc, null values existing in the 'rasterLayer' will remain null in the binary)\n",
    "    gscript.run_command('r.null', quiet=True, map=binary_raster, null='0')\n",
    "    gscript.run_command('r.null', quiet=True, map=tmplayer, null='0')\n",
    "    \n",
    "    ### Compute proportion of pixels of the current class - Administrative units\n",
    "    stat_csv=os.path.join(outputdirectory_admin,\"%s_%s.csv\"%(prefix,cl))\n",
    "    ref_map = gridded_admin_units\n",
    "    gscript.run_command('i.segment.stats', flags='s', map=ref_map, rasters='%s,%s'%(tmplayer,binary_raster), raster_statistics='sum', csvfile=stat_csv, separator='comma', quiet=True, overwrite=True)\n",
    "    output_csv_1=compute_proportion_csv(stat_csv) #Create a new csv containing the proportion\n",
    "    ### Compute proportion of pixels of the current class - Grids\n",
    "    stat_csv=os.path.join(outputdirectory_grid,\"%s_%s.csv\"%(prefix,cl))\n",
    "    ref_map='clumped_grid'\n",
    "    gscript.run_command('i.segment.stats', flags='s', map=ref_map, rasters='%s,%s'%(tmplayer,binary_raster), raster_statistics='sum', csvfile=stat_csv, separator='comma', quiet=True, overwrite=True)\n",
    "    output_csv_2=compute_proportion_csv(stat_csv) #Create a new csv containing the proportion\n",
    "    \n",
    "    ### Remove temporary layer\n",
    "    gscript.run_command('g.remove', quiet=True, flags='f',type='raster',name=tmplayer)\n",
    "    # Return lists\n",
    "    return (binary_raster,output_csv_1,output_csv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def compute_proportion_csv(infile):\n",
    "    '''\n",
    "    Function used in 'proportion_class' function. It take as input the csv from i.segment.stats with the area (in number of pixels)\n",
    "    the sum of pixels of the binary raster and create a new csv with the proportion\n",
    "    '''\n",
    "    # Set the path to the outputfile\n",
    "    head, tail = os.path.split(infile)\n",
    "    root, ext = os.path.splitext(tail)\n",
    "    outfile=os.path.join(head,root+\"_prop\"+ext)\n",
    "    # Create new csv reader and writer objects\n",
    "    reader=csv.reader(open(infile,'r'), delimiter=\",\")\n",
    "    writer=csv.writer(open(outfile,'w'), delimiter=\",\")\n",
    "    # Initialize empty lists\n",
    "    crash_report=[]\n",
    "    content=[]\n",
    "    # Save the first line as header and create the new header\n",
    "    header=reader.next()\n",
    "    new_header=[]\n",
    "    new_header.append(header[0])\n",
    "    index=header[2].find(\"_sum\")\n",
    "    new_header.append(header[2][:index]+'_proportion')\n",
    "    content.append(new_header)  #Create new header with first original column and current class related name for proportion\n",
    "    # Loop through the rest of the rows (header is passed)\n",
    "    for row in reader:\n",
    "        pix_nb=float(row[1]) #Area of the unit (in number of pixels)\n",
    "        class_nb=float(row[2]) #Number of pixels of current class (binary raster)\n",
    "        try:\n",
    "            prop=100*class_nb/pix_nb\n",
    "            content.append([row[0],\"{0:.5f}\".format(prop)])\n",
    "        except ZeroDivisionError:  #If computation of proportion failed because of 'ZeroDivisionError'\n",
    "            crash_report.append(row[0])\n",
    "            content.append([row[0],\"{0:.5f}\".format(0.0)])  # If ZeroDivisionError, set the proportion to zero to avoid errors in next steps\n",
    "            continue\n",
    "    writer.writerows(content)\n",
    "    os.remove(infile)\n",
    "    # Print notification of ZeroDivisionError if it happened\n",
    "    if len(crash_report)>0:\n",
    "        print \"An 'ZeroDivisionError' has been registered for the following <%s>\"%header[0]+\"\\n\".join(crash_report)\n",
    "    # Return the path to the temporary csv file\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VHR Land cover proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proportion of each class of categorical raster computed in: 13 minutes and 26.9 seconds'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save time at starting\n",
    "start = start_processing() \n",
    "## Compute proportion of each class of categorical raster (parallel processing).\n",
    "gscript.run_command('g.region', raster=Land_cover.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "p=Pool(n_jobs) #Create a 'pool' of processes and launch them using 'map' function\n",
    "func=partial(proportion_class,Land_cover.split(\"@\")[0]) # Set fixed argument of the function\n",
    "output=p.map(func,lc_classes_list) # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "temp_rasterlist,temp_csvlist_1,temp_csvlist_2=zip(*output)\n",
    "[TMP_MAPS.append(x) for x in temp_rasterlist]  # Append the name of binary rasters to the list of temporary maps\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_1]  # Append the paths to .csv files to the list of temporary .csv\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_2]  # Append the paths to .csv files to the list of temporary .csv\n",
    "# Print processing time\n",
    "print_processing_time(begintime=start, printmessage=\"Proportion of each class of categorical raster computed in: \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VHR Land use proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proportion of each class of categorical raster computed in: 11 minutes and 55.0 seconds'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save time at starting\n",
    "start = start_processing() \n",
    "## Compute proportion of each class of categorical raster (parallel processing).\n",
    "gscript.run_command('g.region', raster=Land_use.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "p=Pool(n_jobs) #Create a 'pool' of processes and launch them using 'map' function\n",
    "func=partial(proportion_class,Land_use.split(\"@\")[0]) # Set fixed argument of the function\n",
    "output=p.map(func,lu_classes_list) # Launch the processes for as many items in the list (if function with a return, the returned results are ordered thanks to 'map' function)\n",
    "p.close()\n",
    "p.join()\n",
    "temp_rasterlist,temp_csvlist_1,temp_csvlist_2=zip(*output)\n",
    "[TMP_MAPS.append(x) for x in temp_rasterlist]  # Append the name of binary rasters to the list of temporary maps\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_1]  # Append the paths to .csv files to the list of temporary .csv\n",
    "[TMP_CSV.append(x) for x in temp_csvlist_2]  # Append the paths to .csv files to the list of temporary .csv\n",
    "# Print processing time\n",
    "print_processing_time(begintime=start, printmessage=\"Proportion of each class of categorical raster computed in: \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MR Built-up proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An 'ZeroDivisionError' has been registered for the following <cat>2769\n",
      "2077\n",
      "2076\n",
      "2210\n",
      "2770\n",
      "2916\n",
      "2209\n",
      "2485\n",
      "2626\n",
      "2627\n",
      "2915\n",
      "2345\n",
      "2346\n",
      "2484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Proportion of MR Built-up raster computed in: 13 minutes and 14.5 seconds'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save time at starting\n",
    "start = start_processing() \n",
    "## Compute proportion of each class of categorical raster (parallel processing).\n",
    "gscript.run_command('g.region', raster=mr_builtup.split(\"@\")[0])  #Set the region to match the extend of the raster\n",
    "temp_rasterlist,temp_csvlist_1,temp_csvlist_2 = proportion_class(mr_builtup.split(\"@\")[0],mr_built_pixelvalue)\n",
    "TMP_MAPS.append(temp_rasterlist)  # Append the name of binary rasters to the list of temporary maps\n",
    "TMP_CSV.append(temp_csvlist_1)  # Append the paths to .csv files to the list of temporary .csv\n",
    "TMP_CSV.append(temp_csvlist_2)  # Append the paths to .csv files to the list of temporary .csv\n",
    "# Print processing time\n",
    "print_processing_time(begintime=start, printmessage=\"Proportion of MR Built-up raster computed in: \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export layers for archive or visualisation in another GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Binary layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set output folder\n",
    "output_folder = '/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Dakar/binary_rasters'\n",
    "gscript.run_command('r.mask', overwrite=True, raster='maskcopy')  # Apply mask\n",
    "# Export all binary raster\n",
    "for binary_raster in TMP_MAPS:\n",
    "    output_file = os.path.join(output_folder,'Dakar_binary_%s.tiff'%binary_raster)\n",
    "    gscript.run_command('g.region', raster=binary_raster)\n",
    "    gscript.run_command('r.out.gdal', overwrite=True, input=binary_raster, output=output_file, format='GTiff', createopt='COMPRESS=DEFLATE')\n",
    "gscript.run_command('r.mask', flags='r')  # Remove mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Create VHR built-up binary (classes 111,112,113)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-702770bcdf22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r.out.gdal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvhr_builtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GTiff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreateopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'COMPRESS=DEFLATE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r.mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgrass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdel_temp_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Remove temp region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grass' is not defined"
     ]
    }
   ],
   "source": [
    "# Set output folder\n",
    "output_folder = '/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Dakar/binary_rasters'\n",
    "gscript.run_command('r.mask', overwrite=True, raster='maskcopy')  # Apply mask\n",
    "vhr_builtup = 'VHR_builtup'\n",
    "gscript.use_temp_region()  # Define temp region\n",
    "gscript.run_command('g.region', raster=Land_cover)\n",
    "gscript.run_command('r.mapcalc', \n",
    "                    expression='%s=if(%s==111,111,if(%s==112,112,if(%s==113,113,0)))'%(vhr_builtup,Land_cover,Land_cover,Land_cover),\n",
    "                    overwrite=True, quiet=True) # Mapcalc to create binary raster for the expected class 'cl'\n",
    "# Export raster\n",
    "output_file = os.path.join(output_folder,'Dakar_%s.tiff'%vhr_builtup)\n",
    "gscript.run_command('r.out.gdal', overwrite=True, input=vhr_builtup, output=output_file, format='GTiff', createopt='COMPRESS=DEFLATE')\n",
    "gscript.run_command('r.mask', flags='r')  # Remove mask\n",
    "gscript.del_temp_region() # Remove temp region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Clumped Grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set output folder\n",
    "output_folder = '/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Dakar'\n",
    "# Export clumped grid\n",
    "output_file = os.path.join(output_folder,'Dakar_%s.tiff'%clumped_grid)\n",
    "gscript.run_command('g.region', raster=clumped_grid)\n",
    "gscript.run_command('r.out.gdal', overwrite=True, input=clumped_grid, output=output_file, format='GTiff', createopt='COMPRESS=DEFLATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Gridded administrative units (level0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set output folder\n",
    "output_folder = '/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Dakar'\n",
    "# Export gridded admin units (level0)\n",
    "output_file = os.path.join(output_folder,'Dakar_%s.shp'%gridded_vector)\n",
    "gscript.run_command('v.out.ogr', overwrite=True, flags='m', type='area', \n",
    "                    input=gridded_vector, output=output_file, format='ESRI_Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all .csv files with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "\n",
    "def atoi(text):\n",
    "    '''\n",
    "    Function that return integer if text is digit - Used in 'natural_keys' function\n",
    "    '''\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text):   #Return key to be used for sorting string containing numerical values - Used in 'join_csv' function\n",
    "    '''\n",
    "    Trick was found here\n",
    "    https://stackoverflow.com/questions/5967500/how-to-correctly-sort-a-string-with-a-number-inside\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "\n",
    "    '''\n",
    "    import re  #Import needed library\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]  #Split the string\n",
    "\n",
    "\n",
    "def ordered_list_of_path(indir,pattern_A,pattern_B=\"\",pattern_C=\"\"):\n",
    "    '''\n",
    "    Function that return a list of ordered path for the files in the folder 'indir'.\n",
    "    'pattern_A', 'pattern_B', 'pattern_C'\n",
    "    '''\n",
    "    # Make a list of .csv files according to their filename pattern\n",
    "    os.chdir(indir) # Change the current directory to the folder containing all the .csv files\n",
    "    csvList=glob.glob(pattern_A) #Make a list of strings with the name of .csv files\n",
    "    csvList.sort(key=natural_keys) #Sort the list on a human natural order (for strings containing numericals)\n",
    "    if pattern_B !=\"\":\n",
    "        csvList_B=glob.glob(pattern_B) #Make a list of strings with the name of .csv files\n",
    "        csvList_B.sort(key=natural_keys) #Sort the list on a human natural order (for strings containing numericals)\n",
    "        for item in csvList_B:\n",
    "            csvList.append(item)\n",
    "    if pattern_C !=\"\":\n",
    "        csvList_C=glob.glob(pattern_C) #Make a list of strings with the name of .csv files\n",
    "        csvList_C.sort(key=natural_keys) #Sort the list on a human natural order (for strings containing numericals)\n",
    "        for item in csvList_C:\n",
    "            csvList.append(item)\n",
    "    return csvList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_2csv(file1,file2,separator=\";\",join='inner',fillempty='NULL'):\n",
    "    '''\n",
    "    Function that join two csv files according to the first column (primary key).\n",
    "    'file1' and 'file2' wait for complete path (strings) to the corresponding files. Please not that 'file1' is assume to be the left-one in the join\n",
    "    'separator' wait for the character to be considered as .csv delimiter (string)\n",
    "    'join' parameter wait either for 'left' or 'inner' according to type of join\n",
    "    'fillempty' wait for the string to be use to fill the blank when no occurance is found for the join operation\n",
    "    '''\n",
    "    import time,csv,os\n",
    "    header_list=[]\n",
    "    file1_values_dict={}\n",
    "    file2_values_dict={}\n",
    "    reader1=csv.reader(open(file1), delimiter=separator) #Csv reader for file 1\n",
    "    reader2=csv.reader(open(file2), delimiter=separator) #Csv reader for file 2\n",
    "    # Make a list of headers\n",
    "    header_list1=[ x for x in reader1.next()]\n",
    "    header_list2=[ x for x in reader2.next()[1:]]\n",
    "    # Make a list of unique IDs from the first and second table according to type of join\n",
    "    if join=='inner':\n",
    "        id_list=[row[0] for row in reader1]\n",
    "        [id_list.append(row[0]) for row in reader2]\n",
    "        id_list=list(set(id_list))\n",
    "        id_list.sort(key=natural_keys)\n",
    "    if join=='left':\n",
    "        id_list=[row[0] for row in reader1]\n",
    "        id_list=list(set(id_list))\n",
    "        id_list.sort(key=natural_keys)\n",
    "    # Build dictionnary for values of file 1\n",
    "    reader1=csv.reader(open(file1), delimiter=separator)\n",
    "    reader1.next()\n",
    "    values_dict1={rows[0]:rows[1:] for rows in reader1}\n",
    "    # Build dictionnary for values of file 2\n",
    "    reader2=csv.reader(open(file2), delimiter=separator)\n",
    "    reader2.next()\n",
    "    values_dict2={rows[0]:rows[1:] for rows in reader2}\n",
    "    # Built new content\n",
    "    new_content=[]\n",
    "    new_header=header_list1+header_list2\n",
    "    new_content.append(new_header)\n",
    "    for key in id_list:\n",
    "        new_row=[key]\n",
    "        try:\n",
    "            [new_row.append(value) for value in values_dict1[key]]\n",
    "        except:\n",
    "            [new_row.append('%s'%fillempty) for x in header_list1[1:]]\n",
    "        try:\n",
    "            [new_row.append(value) for value in values_dict2[key]]\n",
    "        except:\n",
    "            [new_row.append('%s'%fillempty) for x in header_list2]\n",
    "        new_content.append(new_row)\n",
    "    #Return the result\n",
    "    outfile=gscript.tempfile()\n",
    "    fout=open(outfile,\"w\")\n",
    "    writer=csv.writer(fout, delimiter=separator)\n",
    "    writer.writerows(new_content) #Write multiples rows in the file\n",
    "    time.sleep(0.5) # To be sure the file will not be close to fast (the content could be uncompletly filled)\n",
    "    fout.close()\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_multiplecsv(fileList,outfile,separator=\";\",join='inner', fillempty='NULL', overwrite=False):\n",
    "    '''\n",
    "    Function that apply join on multiple csv files\n",
    "    '''\n",
    "    import os, sys, shutil\n",
    "    # Stop execution if outputfile exitst and can not be overwriten\n",
    "    if os.path.isfile(outfile) and overwrite==False:\n",
    "        print \"File '%s' aleady exists and overwrite option is not enabled.\"%outfile\n",
    "    else:\n",
    "        if os.path.isfile(outfile) and overwrite==True:  # If outputfile exitst and can be overwriten\n",
    "            os.remove(outfile)\n",
    "            #print \"File '%s' will be overwrited.\"%outfile   # Uncomment if you want a print\n",
    "        nbfile=len(fileList)\n",
    "        if nbfile<=1: #Check if there are at least 2 files in the list\n",
    "            sys.exit(\"This function require at least two .csv files to be jointed together.\")\n",
    "        # Copy the list of file in a queue list\n",
    "        queue_list=list(fileList)\n",
    "        # Left join on the two first files\n",
    "        file1=queue_list.pop(0)\n",
    "        file2=queue_list.pop(0)\n",
    "        tmp_file=join_2csv(file1,file2,separator=separator,join=join, fillempty=fillempty)\n",
    "        # Left join on the rest of the files in the list\n",
    "        while len(queue_list)>0:\n",
    "            file2=queue_list.pop(0)\n",
    "            tmp_file=join_2csv(tmp_file,file2,separator=separator,join=join, fillempty=fillempty)\n",
    "        #Copy the temporary file to the desired output path\n",
    "        shutil.copy2(tmp_file,outfile)\n",
    "        # Print what happend\n",
    "        #print \"%s individual .csv files were joint together.\"%nbfile    # Uncomment if you want a print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Join .csv files of statistics\n",
    "for directory in [outputdirectory_grid, outputdirectory_admin]:\n",
    "    allstatfile=os.path.join(directory,\"all_stats.csv\")\n",
    "    pattern_A=\"LC_*_prop.csv\"   #Add all csv with proportions of Land cover classes\n",
    "    pattern_B=\"LU_*_prop.csv\"  #Add all csv with proportions of Land use classes\n",
    "    pattern_C=\"MR_*_prop.csv\" \n",
    "    list_paths = ordered_list_of_path(directory,pattern_A,pattern_B,pattern_C)\n",
    "    join_multiplecsv(list_paths,allstatfile,separator=\",\",join='inner', fillempty='NULL', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of .csv files with statistics to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Admin level 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 92 rows in the dataframe\n"
     ]
    }
   ],
   "source": [
    "## Use pandas for preview of .csv content\n",
    "df_level0 = pd.read_csv(os.path.join(outputdirectory_admin,\"all_stats.csv\"))\n",
    "print \"There are %s rows in the dataframe\"%len(df_level0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>LC_10_proportion</th>\n",
       "      <th>LC_22_proportion</th>\n",
       "      <th>LC_23_proportion</th>\n",
       "      <th>LC_33_proportion</th>\n",
       "      <th>LC_34_proportion</th>\n",
       "      <th>LC_45_proportion</th>\n",
       "      <th>LC_111_proportion</th>\n",
       "      <th>LC_112_proportion</th>\n",
       "      <th>LC_113_proportion</th>\n",
       "      <th>LU_1_proportion</th>\n",
       "      <th>LU_2_proportion</th>\n",
       "      <th>LU_3_proportion</th>\n",
       "      <th>LU_4_proportion</th>\n",
       "      <th>LU_5_proportion</th>\n",
       "      <th>LU_6_proportion</th>\n",
       "      <th>LU_7_proportion</th>\n",
       "      <th>LU_8_proportion</th>\n",
       "      <th>MR_1_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>90</td>\n",
       "      <td>4.14186</td>\n",
       "      <td>2.53890</td>\n",
       "      <td>3.49121</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00837</td>\n",
       "      <td>47.07824</td>\n",
       "      <td>18.13912</td>\n",
       "      <td>16.40363</td>\n",
       "      <td>8.19866</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.48147</td>\n",
       "      <td>29.29234</td>\n",
       "      <td>26.56825</td>\n",
       "      <td>8.89439</td>\n",
       "      <td>3.28561</td>\n",
       "      <td>30.47794</td>\n",
       "      <td>91.56137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>92</td>\n",
       "      <td>6.16394</td>\n",
       "      <td>2.32306</td>\n",
       "      <td>5.33746</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00288</td>\n",
       "      <td>38.47639</td>\n",
       "      <td>27.32008</td>\n",
       "      <td>16.67622</td>\n",
       "      <td>3.69996</td>\n",
       "      <td>13.22556</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.82596</td>\n",
       "      <td>2.69384</td>\n",
       "      <td>54.67320</td>\n",
       "      <td>6.84909</td>\n",
       "      <td>16.33996</td>\n",
       "      <td>3.39238</td>\n",
       "      <td>92.63615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>93</td>\n",
       "      <td>1.43904</td>\n",
       "      <td>1.11119</td>\n",
       "      <td>2.31706</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>46.07337</td>\n",
       "      <td>29.22652</td>\n",
       "      <td>15.45421</td>\n",
       "      <td>4.37860</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.10331</td>\n",
       "      <td>5.92561</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57.30684</td>\n",
       "      <td>6.51643</td>\n",
       "      <td>20.75077</td>\n",
       "      <td>7.39703</td>\n",
       "      <td>88.18728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>95</td>\n",
       "      <td>13.90201</td>\n",
       "      <td>8.18194</td>\n",
       "      <td>7.58257</td>\n",
       "      <td>0.19749</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>33.79304</td>\n",
       "      <td>20.68137</td>\n",
       "      <td>10.10989</td>\n",
       "      <td>5.55074</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03407</td>\n",
       "      <td>2.38112</td>\n",
       "      <td>45.81027</td>\n",
       "      <td>34.61187</td>\n",
       "      <td>11.39264</td>\n",
       "      <td>0.36809</td>\n",
       "      <td>5.40193</td>\n",
       "      <td>92.56219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>96</td>\n",
       "      <td>2.42438</td>\n",
       "      <td>2.32184</td>\n",
       "      <td>8.41560</td>\n",
       "      <td>0.15801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>38.04187</td>\n",
       "      <td>41.01151</td>\n",
       "      <td>7.38604</td>\n",
       "      <td>0.24075</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.30591</td>\n",
       "      <td>0.50372</td>\n",
       "      <td>0.50732</td>\n",
       "      <td>67.14672</td>\n",
       "      <td>19.87354</td>\n",
       "      <td>0.74341</td>\n",
       "      <td>10.91938</td>\n",
       "      <td>99.18418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>97</td>\n",
       "      <td>5.22106</td>\n",
       "      <td>5.08049</td>\n",
       "      <td>7.81146</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>35.53913</td>\n",
       "      <td>35.86044</td>\n",
       "      <td>5.80834</td>\n",
       "      <td>0.32735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.74403</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.08942</td>\n",
       "      <td>24.73067</td>\n",
       "      <td>10.65976</td>\n",
       "      <td>50.86511</td>\n",
       "      <td>5.91100</td>\n",
       "      <td>90.82697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>98</td>\n",
       "      <td>7.96489</td>\n",
       "      <td>5.06971</td>\n",
       "      <td>15.86843</td>\n",
       "      <td>0.96281</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>29.11977</td>\n",
       "      <td>37.21976</td>\n",
       "      <td>3.67354</td>\n",
       "      <td>0.11935</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.49157</td>\n",
       "      <td>0.83214</td>\n",
       "      <td>0.52367</td>\n",
       "      <td>7.66176</td>\n",
       "      <td>18.49773</td>\n",
       "      <td>67.06992</td>\n",
       "      <td>3.92321</td>\n",
       "      <td>97.80284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>99</td>\n",
       "      <td>4.02054</td>\n",
       "      <td>3.35277</td>\n",
       "      <td>1.90050</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>48.92888</td>\n",
       "      <td>16.84599</td>\n",
       "      <td>20.04965</td>\n",
       "      <td>4.89960</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.23071</td>\n",
       "      <td>6.34851</td>\n",
       "      <td>69.79553</td>\n",
       "      <td>14.26131</td>\n",
       "      <td>0.33849</td>\n",
       "      <td>3.02545</td>\n",
       "      <td>79.02314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat  LC_10_proportion  LC_22_proportion  LC_23_proportion  \\\n",
       "84   90           4.14186           2.53890           3.49121   \n",
       "85   92           6.16394           2.32306           5.33746   \n",
       "86   93           1.43904           1.11119           2.31706   \n",
       "87   95          13.90201           8.18194           7.58257   \n",
       "88   96           2.42438           2.32184           8.41560   \n",
       "89   97           5.22106           5.08049           7.81146   \n",
       "90   98           7.96489           5.06971          15.86843   \n",
       "91   99           4.02054           3.35277           1.90050   \n",
       "\n",
       "    LC_33_proportion  LC_34_proportion  LC_45_proportion  LC_111_proportion  \\\n",
       "84           0.00000           0.00837          47.07824           18.13912   \n",
       "85           0.00000           0.00288          38.47639           27.32008   \n",
       "86           0.00000           0.00000          46.07337           29.22652   \n",
       "87           0.19749           0.00095          33.79304           20.68137   \n",
       "88           0.15801           0.00000          38.04187           41.01151   \n",
       "89           4.35000           0.00173          35.53913           35.86044   \n",
       "90           0.96281           0.00174          29.11977           37.21976   \n",
       "91           0.00000           0.00206          48.92888           16.84599   \n",
       "\n",
       "    LC_112_proportion  LC_113_proportion  LU_1_proportion  LU_2_proportion  \\\n",
       "84           16.40363            8.19866          0.00000          0.00000   \n",
       "85           16.67622            3.69996         13.22556          0.00000   \n",
       "86           15.45421            4.37860          0.00000          2.10331   \n",
       "87           10.10989            5.55074          0.00000          0.03407   \n",
       "88            7.38604            0.24075          0.00000          0.30591   \n",
       "89            5.80834            0.32735          0.00000          7.74403   \n",
       "90            3.67354            0.11935          0.00000          1.49157   \n",
       "91           20.04965            4.89960          0.00000          0.00000   \n",
       "\n",
       "    LU_3_proportion  LU_4_proportion  LU_5_proportion  LU_6_proportion  \\\n",
       "84          1.48147         29.29234         26.56825          8.89439   \n",
       "85          2.82596          2.69384         54.67320          6.84909   \n",
       "86          5.92561          0.00000         57.30684          6.51643   \n",
       "87          2.38112         45.81027         34.61187         11.39264   \n",
       "88          0.50372          0.50732         67.14672         19.87354   \n",
       "89          0.00000          0.08942         24.73067         10.65976   \n",
       "90          0.83214          0.52367          7.66176         18.49773   \n",
       "91          6.23071          6.34851         69.79553         14.26131   \n",
       "\n",
       "    LU_7_proportion  LU_8_proportion  MR_1_proportion  \n",
       "84          3.28561         30.47794         91.56137  \n",
       "85         16.33996          3.39238         92.63615  \n",
       "86         20.75077          7.39703         88.18728  \n",
       "87          0.36809          5.40193         92.56219  \n",
       "88          0.74341         10.91938         99.18418  \n",
       "89         50.86511          5.91100         90.82697  \n",
       "90         67.06992          3.92321         97.80284  \n",
       "91          0.33849          3.02545         79.02314  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display tail of the dataframe\n",
    "df_level0.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20049 rows in the dataframe\n"
     ]
    }
   ],
   "source": [
    "## Use pandas for preview of .csv content\n",
    "df_grid = pd.read_csv(os.path.join(outputdirectory_grid,\"all_stats.csv\"))\n",
    "print \"There are %s rows in the dataframe\"%len(df_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>LC_10_proportion</th>\n",
       "      <th>LC_22_proportion</th>\n",
       "      <th>LC_23_proportion</th>\n",
       "      <th>LC_33_proportion</th>\n",
       "      <th>LC_34_proportion</th>\n",
       "      <th>LC_45_proportion</th>\n",
       "      <th>LC_111_proportion</th>\n",
       "      <th>LC_112_proportion</th>\n",
       "      <th>LC_113_proportion</th>\n",
       "      <th>LU_1_proportion</th>\n",
       "      <th>LU_2_proportion</th>\n",
       "      <th>LU_3_proportion</th>\n",
       "      <th>LU_4_proportion</th>\n",
       "      <th>LU_5_proportion</th>\n",
       "      <th>LU_6_proportion</th>\n",
       "      <th>LU_7_proportion</th>\n",
       "      <th>LU_8_proportion</th>\n",
       "      <th>MR_1_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>20042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.58750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.61000</td>\n",
       "      <td>24.44000</td>\n",
       "      <td>43.28750</td>\n",
       "      <td>0.07500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.84000</td>\n",
       "      <td>61.8325</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>20043</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45.38500</td>\n",
       "      <td>8.41000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.85000</td>\n",
       "      <td>13.76000</td>\n",
       "      <td>2.59500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.6600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.84500</td>\n",
       "      <td>3.4950</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20043</th>\n",
       "      <td>20044</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>20.76581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.59745</td>\n",
       "      <td>0.63674</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.56763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20044</th>\n",
       "      <td>20045</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.60881</td>\n",
       "      <td>24.84916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.17438</td>\n",
       "      <td>0.15084</td>\n",
       "      <td>1.58136</td>\n",
       "      <td>49.63546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.56250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20045</th>\n",
       "      <td>20046</td>\n",
       "      <td>0.15500</td>\n",
       "      <td>14.55500</td>\n",
       "      <td>0.37000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.62750</td>\n",
       "      <td>10.87500</td>\n",
       "      <td>20.83750</td>\n",
       "      <td>5.58000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.13750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>34.86250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>20047</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.45250</td>\n",
       "      <td>31.26000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.08750</td>\n",
       "      <td>0.86250</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.40500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.59500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20047</th>\n",
       "      <td>20048</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.32500</td>\n",
       "      <td>2.62250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.55500</td>\n",
       "      <td>0.39250</td>\n",
       "      <td>1.68250</td>\n",
       "      <td>8.42250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.59000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>90.41000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.52423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20048</th>\n",
       "      <td>20049</td>\n",
       "      <td>2.74968</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>49.92149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.32883</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.05456</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.94544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.54545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat  LC_10_proportion  LC_22_proportion  LC_23_proportion  \\\n",
       "20041  20042           0.00000          23.58750           0.00000   \n",
       "20042  20043           0.00000          45.38500           8.41000   \n",
       "20043  20044           0.00000           0.00000          20.76581   \n",
       "20044  20045           0.00000           9.60881          24.84916   \n",
       "20045  20046           0.15500          14.55500           0.37000   \n",
       "20046  20047           0.00000          11.45250          31.26000   \n",
       "20047  20048           0.00000           6.32500           2.62250   \n",
       "20048  20049           2.74968           0.00000          49.92149   \n",
       "\n",
       "       LC_33_proportion  LC_34_proportion  LC_45_proportion  \\\n",
       "20041               0.0               0.0           8.61000   \n",
       "20042               0.0               0.0          29.85000   \n",
       "20043               0.0               0.0          78.59745   \n",
       "20044               0.0               0.0          14.17438   \n",
       "20045               0.0               0.0          47.62750   \n",
       "20046               0.0               0.0          56.08750   \n",
       "20047               0.0               0.0          80.55500   \n",
       "20048               0.0               0.0          47.32883   \n",
       "\n",
       "       LC_111_proportion  LC_112_proportion  LC_113_proportion  \\\n",
       "20041           24.44000           43.28750            0.07500   \n",
       "20042           13.76000            2.59500            0.00000   \n",
       "20043            0.63674            0.00000            0.00000   \n",
       "20044            0.15084            1.58136           49.63546   \n",
       "20045           10.87500           20.83750            5.58000   \n",
       "20046            0.86250            0.33750            0.00000   \n",
       "20047            0.39250            1.68250            8.42250   \n",
       "20048            0.00000            0.00000            0.00000   \n",
       "\n",
       "       LU_1_proportion  LU_2_proportion  LU_3_proportion  LU_4_proportion  \\\n",
       "20041              0.0           9.3275              0.0         28.84000   \n",
       "20042              0.0          29.6600              0.0         66.84500   \n",
       "20043              0.0           0.0000              0.0        100.00000   \n",
       "20044              0.0           0.0000              0.0        100.00000   \n",
       "20045              0.0           0.0000              0.0         65.13750   \n",
       "20046              0.0           0.0000              0.0         80.40500   \n",
       "20047              0.0           0.0000              0.0          9.59000   \n",
       "20048              0.0           0.0000              0.0         80.05456   \n",
       "\n",
       "       LU_5_proportion  LU_6_proportion  LU_7_proportion  LU_8_proportion  \\\n",
       "20041          61.8325          0.00000              0.0              0.0   \n",
       "20042           3.4950          0.00000              0.0              0.0   \n",
       "20043           0.0000          0.00000              0.0              0.0   \n",
       "20044           0.0000          0.00000              0.0              0.0   \n",
       "20045           0.0000         34.86250              0.0              0.0   \n",
       "20046           0.0000         19.59500              0.0              0.0   \n",
       "20047           0.0000         90.41000              0.0              0.0   \n",
       "20048           0.0000         19.94544              0.0              0.0   \n",
       "\n",
       "       MR_1_proportion  \n",
       "20041         88.12500  \n",
       "20042         13.75000  \n",
       "20043         45.56763  \n",
       "20044         85.56250  \n",
       "20045         63.37500  \n",
       "20046          4.12500  \n",
       "20047          3.52423  \n",
       "20048          4.54545  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display tail of the dataframe\n",
    "df_grid.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Random Forest\n",
    "RandomForest(output_weighting_layer,vector.split(\"@\")[0],id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.population.density.py -a -f --overwrite vector=admin_level0@PERMANENT land_cover=landcover@PERMANENT land_use=landuse@PERMANENT tile_size=100 id=Sect_ID population=pop_Total output=Ouaga_lc_lu_100m_weighting_RF plot=/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Ouagadougou/RF_feature_importance.png log_file=/media/tais/My_Book_1/MAUPP/Traitement/Population_modelling_dasymetry/Results/Ouagadougou/RF_log n_jobs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Re-allocate population count from level 0 to the grid level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v.area.weigh --overwrite vector=admin_level0_100m_gridded@PERMANENT column=pop_Total weight=Ouaga_lc_lu_100m_weighting_RF@PERMANENT output=Ouaga_lc_lu_100m_pop_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove all temporary layers\n",
    "# raster corresponding to administrative units (level0)\n",
    "gscript.run_command('g.remove', quiet=True, flags='f',type='raster',name=gridded_admin_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
